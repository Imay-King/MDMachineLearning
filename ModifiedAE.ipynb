{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed(2020) #set random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the processed data, note that we've already converted the dcd/pdb file to csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca=pd.read_csv('./Ala13/PCAanalysis.csv',names=['PCA1','PCA2'])\n",
    "df_cor=pd.read_csv('./Ala13/Atoms_coordinates_whole.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0168</td>\n",
       "      <td>-0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0177</td>\n",
       "      <td>-0.001320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PCA1      PCA2\n",
       "0  0.0162  0.002330\n",
       "1  0.0164  0.000557\n",
       "2  0.0168 -0.000337\n",
       "3  0.0175 -0.001910\n",
       "4  0.0177 -0.001320"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.130003</td>\n",
       "      <td>30.730001</td>\n",
       "      <td>33.320004</td>\n",
       "      <td>28.780001</td>\n",
       "      <td>30.370003</td>\n",
       "      <td>32.850002</td>\n",
       "      <td>27.740002</td>\n",
       "      <td>31.210001</td>\n",
       "      <td>33.570000</td>\n",
       "      <td>28.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.540001</td>\n",
       "      <td>20.970001</td>\n",
       "      <td>20.630001</td>\n",
       "      <td>18.210001</td>\n",
       "      <td>21.800001</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>19.960001</td>\n",
       "      <td>20.500002</td>\n",
       "      <td>17.490002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.582726</td>\n",
       "      <td>31.034544</td>\n",
       "      <td>33.609142</td>\n",
       "      <td>29.322193</td>\n",
       "      <td>30.378710</td>\n",
       "      <td>33.246048</td>\n",
       "      <td>28.169268</td>\n",
       "      <td>31.027327</td>\n",
       "      <td>34.018612</td>\n",
       "      <td>29.069057</td>\n",
       "      <td>...</td>\n",
       "      <td>18.046659</td>\n",
       "      <td>21.080175</td>\n",
       "      <td>19.482227</td>\n",
       "      <td>17.698109</td>\n",
       "      <td>21.676388</td>\n",
       "      <td>18.441927</td>\n",
       "      <td>18.062536</td>\n",
       "      <td>20.435606</td>\n",
       "      <td>19.408522</td>\n",
       "      <td>16.636789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.547211</td>\n",
       "      <td>30.999948</td>\n",
       "      <td>33.498272</td>\n",
       "      <td>28.881954</td>\n",
       "      <td>30.967804</td>\n",
       "      <td>32.882378</td>\n",
       "      <td>29.850468</td>\n",
       "      <td>30.103348</td>\n",
       "      <td>33.687733</td>\n",
       "      <td>28.909615</td>\n",
       "      <td>...</td>\n",
       "      <td>17.698475</td>\n",
       "      <td>21.072111</td>\n",
       "      <td>20.966135</td>\n",
       "      <td>17.106026</td>\n",
       "      <td>21.194897</td>\n",
       "      <td>19.720905</td>\n",
       "      <td>17.171005</td>\n",
       "      <td>20.400530</td>\n",
       "      <td>21.533232</td>\n",
       "      <td>16.229221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.889790</td>\n",
       "      <td>30.885441</td>\n",
       "      <td>33.714222</td>\n",
       "      <td>29.036554</td>\n",
       "      <td>30.401567</td>\n",
       "      <td>32.932556</td>\n",
       "      <td>29.474493</td>\n",
       "      <td>29.073942</td>\n",
       "      <td>33.540764</td>\n",
       "      <td>28.938217</td>\n",
       "      <td>...</td>\n",
       "      <td>18.102945</td>\n",
       "      <td>22.408243</td>\n",
       "      <td>19.916569</td>\n",
       "      <td>17.357298</td>\n",
       "      <td>23.642900</td>\n",
       "      <td>19.738064</td>\n",
       "      <td>17.475031</td>\n",
       "      <td>21.699007</td>\n",
       "      <td>19.404203</td>\n",
       "      <td>16.474821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.751440</td>\n",
       "      <td>29.981630</td>\n",
       "      <td>33.914619</td>\n",
       "      <td>28.425182</td>\n",
       "      <td>30.937717</td>\n",
       "      <td>33.022114</td>\n",
       "      <td>29.750643</td>\n",
       "      <td>31.394354</td>\n",
       "      <td>33.635334</td>\n",
       "      <td>28.520418</td>\n",
       "      <td>...</td>\n",
       "      <td>18.586025</td>\n",
       "      <td>21.225840</td>\n",
       "      <td>20.214525</td>\n",
       "      <td>17.992739</td>\n",
       "      <td>22.343639</td>\n",
       "      <td>20.065355</td>\n",
       "      <td>17.446964</td>\n",
       "      <td>20.361906</td>\n",
       "      <td>19.368549</td>\n",
       "      <td>17.718796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0  30.130003  30.730001  33.320004  28.780001  30.370003  32.850002   \n",
       "1  30.582726  31.034544  33.609142  29.322193  30.378710  33.246048   \n",
       "2  27.547211  30.999948  33.498272  28.881954  30.967804  32.882378   \n",
       "3  27.889790  30.885441  33.714222  29.036554  30.401567  32.932556   \n",
       "4  27.751440  29.981630  33.914619  28.425182  30.937717  33.022114   \n",
       "\n",
       "         6          7          8          9      ...            188  \\\n",
       "0  27.740002  31.210001  33.570000  28.580000    ...      18.540001   \n",
       "1  28.169268  31.027327  34.018612  29.069057    ...      18.046659   \n",
       "2  29.850468  30.103348  33.687733  28.909615    ...      17.698475   \n",
       "3  29.474493  29.073942  33.540764  28.938217    ...      18.102945   \n",
       "4  29.750643  31.394354  33.635334  28.520418    ...      18.586025   \n",
       "\n",
       "         189        190        191        192        193        194  \\\n",
       "0  20.970001  20.630001  18.210001  21.800001  19.700001  18.200001   \n",
       "1  21.080175  19.482227  17.698109  21.676388  18.441927  18.062536   \n",
       "2  21.072111  20.966135  17.106026  21.194897  19.720905  17.171005   \n",
       "3  22.408243  19.916569  17.357298  23.642900  19.738064  17.475031   \n",
       "4  21.225840  20.214525  17.992739  22.343639  20.065355  17.446964   \n",
       "\n",
       "         195        196        197  \n",
       "0  19.960001  20.500002  17.490002  \n",
       "1  20.435606  19.408522  16.636789  \n",
       "2  20.400530  21.533232  16.229221  \n",
       "3  21.699007  19.404203  16.474821  \n",
       "4  20.361906  19.368549  17.718796  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the PCA values and its corresponding trajectories,here we regard PC1/PC2 values as labels in machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.62000000e-02, 2.33000000e-03, 3.01300030e+01, 3.07300014e+01,\n",
       "        3.33200035e+01, 2.87800007e+01, 3.03700028e+01, 3.28500023e+01,\n",
       "        2.77400017e+01, 3.12100010e+01, 3.35699997e+01, 2.85799999e+01,\n",
       "        3.03899994e+01, 3.13400002e+01, 2.79200001e+01, 2.94400024e+01,\n",
       "        3.09200020e+01, 2.90000000e+01, 3.14500027e+01, 3.06500015e+01,\n",
       "        2.90800018e+01, 3.16399994e+01, 2.92200012e+01, 3.00400009e+01,\n",
       "        3.27800026e+01, 2.88800030e+01, 2.94800014e+01, 3.03199997e+01,\n",
       "        2.85600014e+01, 2.88500023e+01, 2.98400021e+01, 2.76200008e+01,\n",
       "        3.04900017e+01, 2.96400032e+01, 2.91000004e+01, 3.10700016e+01,\n",
       "        2.84600029e+01, 2.84799995e+01, 3.25200005e+01, 2.82200012e+01,\n",
       "        2.89000015e+01, 3.02100010e+01, 2.72100029e+01, 2.86100006e+01,\n",
       "        2.99600010e+01, 2.65200024e+01, 2.76300030e+01, 2.97900009e+01,\n",
       "        2.69100017e+01, 2.98400021e+01, 2.89300003e+01, 2.58100014e+01,\n",
       "        3.02300034e+01, 2.88900013e+01, 2.57200012e+01, 3.17500019e+01,\n",
       "        2.75700016e+01, 2.59799995e+01, 2.95700035e+01, 2.70600014e+01,\n",
       "        2.49800014e+01, 2.90699997e+01, 2.69800014e+01, 2.71700020e+01,\n",
       "        2.94400024e+01, 2.57700005e+01, 2.74600010e+01, 2.86900024e+01,\n",
       "        2.52600002e+01, 2.88500023e+01, 2.90200024e+01, 2.59200001e+01,\n",
       "        2.72600002e+01, 2.71800022e+01, 2.50400009e+01, 2.66200028e+01,\n",
       "        2.66200028e+01, 2.70900002e+01, 2.76100006e+01, 2.66300011e+01,\n",
       "        2.74000015e+01, 2.72299995e+01, 2.52700024e+01, 2.85499992e+01,\n",
       "        2.81000023e+01, 2.47800026e+01, 2.75400009e+01, 2.57400017e+01,\n",
       "        2.49900017e+01, 2.70500011e+01, 2.53000031e+01, 2.39500027e+01,\n",
       "        2.81700020e+01, 2.50100021e+01, 2.59200001e+01, 2.82000008e+01,\n",
       "        2.35600014e+01, 2.59099998e+01, 2.90000000e+01, 2.30000019e+01,\n",
       "        2.70800018e+01, 2.68100014e+01, 2.29400024e+01, 2.58700008e+01,\n",
       "        2.65400009e+01, 2.21300011e+01, 2.49800014e+01, 2.59099998e+01,\n",
       "        2.34000015e+01, 2.67500019e+01, 2.45600014e+01, 2.28800011e+01,\n",
       "        2.67800026e+01, 2.39099998e+01, 2.33700008e+01, 2.80700016e+01,\n",
       "        2.37200012e+01, 2.32600021e+01, 2.55600014e+01, 2.28700028e+01,\n",
       "        2.25200005e+01, 2.50800018e+01, 2.40300007e+01, 2.44400005e+01,\n",
       "        2.50200005e+01, 2.34000015e+01, 2.49300003e+01, 2.38100014e+01,\n",
       "        2.37800007e+01, 2.63900013e+01, 2.35300026e+01, 2.36900024e+01,\n",
       "        2.41200028e+01, 2.25600014e+01, 2.28199997e+01, 2.37700005e+01,\n",
       "        2.17600021e+01, 2.49800014e+01, 2.37700005e+01, 2.24100017e+01,\n",
       "        2.54700012e+01, 2.29400024e+01, 2.13300018e+01, 2.69500008e+01,\n",
       "        2.32700005e+01, 2.11600017e+01, 2.51500015e+01, 2.14600010e+01,\n",
       "        2.15000000e+01, 2.53899994e+01, 2.07100010e+01, 2.05700016e+01,\n",
       "        2.47400017e+01, 2.10799999e+01, 2.27100010e+01, 2.42300014e+01,\n",
       "        1.97500019e+01, 2.30000019e+01, 2.45100021e+01, 1.94300003e+01,\n",
       "        2.44700012e+01, 2.27500000e+01, 1.97200012e+01, 2.26500015e+01,\n",
       "        2.22299995e+01, 1.87100010e+01, 2.21700001e+01, 2.19600010e+01,\n",
       "        2.07600021e+01, 2.29400024e+01, 2.05599995e+01, 2.09000015e+01,\n",
       "        2.25900002e+01, 1.99200020e+01, 2.19600010e+01, 2.34799995e+01,\n",
       "        2.03100014e+01, 2.12600021e+01, 2.11300011e+01, 1.91900024e+01,\n",
       "        2.10400009e+01, 2.06800003e+01, 2.12700005e+01, 2.18600006e+01,\n",
       "        2.04200001e+01, 2.12800007e+01, 2.19100017e+01, 1.89700012e+01,\n",
       "        2.26400013e+01, 2.24600010e+01, 1.85400009e+01, 2.09700012e+01,\n",
       "        2.06300011e+01, 1.82100010e+01, 2.18000011e+01, 1.97000008e+01,\n",
       "        1.82000008e+01, 1.99600010e+01, 2.05000019e+01, 1.74900017e+01],\n",
       "       [1.64000000e-02, 5.57000000e-04, 3.05827255e+01, 3.10345440e+01,\n",
       "        3.36091423e+01, 2.93221932e+01, 3.03787098e+01, 3.32460480e+01,\n",
       "        2.81692676e+01, 3.10273266e+01, 3.40186119e+01, 2.90690575e+01,\n",
       "        3.03275661e+01, 3.17423820e+01, 2.84527416e+01, 2.93733921e+01,\n",
       "        3.12636261e+01, 2.95374031e+01, 3.13431072e+01, 3.10147667e+01,\n",
       "        2.92576084e+01, 3.14215679e+01, 2.95929127e+01, 2.97234745e+01,\n",
       "        3.27747650e+01, 2.90629883e+01, 2.97507858e+01, 3.02569428e+01,\n",
       "        2.87505169e+01, 2.90006523e+01, 2.99801941e+01, 2.78212147e+01,\n",
       "        3.08601665e+01, 2.95998669e+01, 2.91163406e+01, 3.13642921e+01,\n",
       "        2.84202919e+01, 2.84271011e+01, 3.28558578e+01, 2.83496342e+01,\n",
       "        2.87536640e+01, 3.06288319e+01, 2.71476231e+01, 2.88039532e+01,\n",
       "        3.06419582e+01, 2.62702351e+01, 2.79429550e+01, 2.98624764e+01,\n",
       "        2.71399307e+01, 2.98889599e+01, 2.89360676e+01, 2.61052418e+01,\n",
       "        3.03314285e+01, 2.87045326e+01, 2.61204052e+01, 3.18368397e+01,\n",
       "        2.76078358e+01, 2.61679611e+01, 2.95915146e+01, 2.71973705e+01,\n",
       "        2.52176971e+01, 2.89462910e+01, 2.69424801e+01, 2.73285370e+01,\n",
       "        2.95787277e+01, 2.57604942e+01, 2.76631241e+01, 2.88163853e+01,\n",
       "        2.54733696e+01, 2.91532822e+01, 2.90183411e+01, 2.58570843e+01,\n",
       "        2.74176426e+01, 2.73177147e+01, 2.49239464e+01, 2.68425560e+01,\n",
       "        2.67732601e+01, 2.69601288e+01, 2.78256130e+01, 2.66812782e+01,\n",
       "        2.71186657e+01, 2.75803986e+01, 2.52598247e+01, 2.83253365e+01,\n",
       "        2.83481808e+01, 2.47203293e+01, 2.72440605e+01, 2.60867958e+01,\n",
       "        2.49959660e+01, 2.64953384e+01, 2.56600132e+01, 2.41165504e+01,\n",
       "        2.79815712e+01, 2.52983017e+01, 2.57849255e+01, 2.80749836e+01,\n",
       "        2.38552208e+01, 2.57019653e+01, 2.89921131e+01, 2.34636650e+01,\n",
       "        2.68557243e+01, 2.67119179e+01, 2.31756763e+01, 2.57695961e+01,\n",
       "        2.65177689e+01, 2.22614307e+01, 2.49740086e+01, 2.57177200e+01,\n",
       "        2.36635246e+01, 2.65111980e+01, 2.44087543e+01, 2.30510216e+01,\n",
       "        2.65403767e+01, 2.37881756e+01, 2.31817989e+01, 2.79314442e+01,\n",
       "        2.34396172e+01, 2.34874611e+01, 2.54489098e+01, 2.24287643e+01,\n",
       "        2.28097420e+01, 2.52715073e+01, 2.37180424e+01, 2.45256233e+01,\n",
       "        2.46443596e+01, 2.30810165e+01, 2.49027882e+01, 2.33993130e+01,\n",
       "        2.31943665e+01, 2.64083748e+01, 2.32294006e+01, 2.36362419e+01,\n",
       "        2.39831753e+01, 2.23198032e+01, 2.28665466e+01, 2.34644375e+01,\n",
       "        2.15132217e+01, 2.49306049e+01, 2.36657715e+01, 2.23288364e+01,\n",
       "        2.56055908e+01, 2.27272453e+01, 2.14576549e+01, 2.70928478e+01,\n",
       "        2.27066860e+01, 2.17926826e+01, 2.51001301e+01, 2.13005848e+01,\n",
       "        2.16815834e+01, 2.52498913e+01, 2.05108261e+01, 2.07495117e+01,\n",
       "        2.46492767e+01, 2.09451351e+01, 2.28824520e+01, 2.40094910e+01,\n",
       "        1.96839390e+01, 2.31928616e+01, 2.38062859e+01, 1.95820694e+01,\n",
       "        2.47083263e+01, 2.27033176e+01, 1.94768295e+01, 2.24426498e+01,\n",
       "        2.25565529e+01, 1.85390225e+01, 2.16570435e+01, 2.17390194e+01,\n",
       "        2.03423519e+01, 2.27717361e+01, 2.04466648e+01, 2.03817749e+01,\n",
       "        2.21170864e+01, 1.98026180e+01, 2.16592979e+01, 2.26398086e+01,\n",
       "        2.02943077e+01, 2.02737083e+01, 2.06117611e+01, 1.92697067e+01,\n",
       "        1.97494507e+01, 2.01806641e+01, 2.12834339e+01, 2.07540321e+01,\n",
       "        1.98553753e+01, 2.11853619e+01, 2.08264427e+01, 1.84081936e+01,\n",
       "        2.24104939e+01, 2.16515751e+01, 1.80466595e+01, 2.10801754e+01,\n",
       "        1.94822273e+01, 1.76981087e+01, 2.16763878e+01, 1.84419270e+01,\n",
       "        1.80625362e+01, 2.04356060e+01, 1.94085217e+01, 1.66367893e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=np.concatenate((df_pca,df_cor),axis=1)\n",
    "train_data.shape, df_pca.shape, df_cor.shape\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_data)\n",
    "train_dataset=train_data[:2000]\n",
    "test_dataset=train_data[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_pd=pd.DataFrame(train_dataset)\n",
    "#train_dataset_pd\n",
    "test_dataset_pd=pd.DataFrame(test_dataset)\n",
    "#train_dataset_pd.to_csv('train_data.csv',header=None,index=None)\n",
    "#test_dataset_pd.to_csv('test_data_500.csv',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2), (2000, 198), (500, 2), (500, 198))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test_dataset[:,:2]\n",
    "Y_test=test_dataset[:,2:]\n",
    "X_train=train_dataset[:,:2]\n",
    "Y_train=train_dataset[:,2:]\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "# note that we must define two minmaxscalers\n",
    "scalar1 = MinMaxScaler()\n",
    "scalar2 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train=scalar1.fit_transform(X_train)\n",
    "Y_scaled_train=scalar2.fit_transform(Y_train)\n",
    "X_scaled_test=scalar1.transform(X_test)\n",
    "Y_scaled_test=scalar2.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras.losses import mean_squared_error, binary_crossentropy\n",
    "from keras import objectives\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "intermediate_dim_1=16\n",
    "intermediate_dim_2=32\n",
    "intermediate_dim_3=64\n",
    "original_dim=198\n",
    "#Encoder part\n",
    "input_net=Input(shape=(original_dim,), name=\"embeding\")\n",
    "encoded_h_3 = Dense(intermediate_dim_3, activation='relu', name=\"hiddenLayer1\",kernel_initializer='normal')(input_net)\n",
    "encoded_h_2 = Dense(intermediate_dim_2, activation='relu', name=\"hiddenLayer2\",kernel_initializer='normal')(encoded_h_3)\n",
    "encoded_h_1 = Dense(intermediate_dim_1, activation='relu', name=\"hiddenLayer3\",kernel_initializer='normal')(encoded_h_2)\n",
    "PCA=Dense(latent_dim, activation='sigmoid', name=\"encode_out\",kernel_initializer='normal')(encoded_h_1)\n",
    "\n",
    "#PCA=Dense(latent_dim, activation='relu', name=\"encode_out\")(input_net)\n",
    "#Decoder part\n",
    "decoded_h_1= Dense(intermediate_dim_1,kernel_initializer='normal', activation='relu', name=\"hiddenLayer4\")(PCA)\n",
    "decoded_h_2= Dense(intermediate_dim_2,kernel_initializer='normal', activation='relu', name=\"hiddenLayer5\")(decoded_h_1)\n",
    "decoded_h_3= Dense(intermediate_dim_3,kernel_initializer='normal', activation='relu', name=\"hiddenLayer6\")(decoded_h_2)\n",
    "decoded = Dense(original_dim,kernel_initializer='normal', activation='sigmoid', name=\"decode_out\")(decoded_h_3)\n",
    "#decoded = Dense(original_dim, activation='sigmoid', name=\"decode_out\")(PCA)\n",
    "# end-to-end autoencoder\n",
    "autoencoder = Model(inputs=input_net, outputs=[PCA, decoded], name=\"AutoEncoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function, we use the mse loss function in two different part in modified AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_loss(y_true, y_pred):\n",
    "    return mean_squared_error(y_true,y_pred)\n",
    "\n",
    "# loss compile\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99, epsilon=1e-08)\n",
    "autoencoder.compile(optimizer=adam,\n",
    "              loss={'encode_out': latent_loss,'decode_out': latent_loss},\n",
    "              loss_weights={'encode_out':1, 'decode_out': 1},\n",
    "              metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the structure of autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeding (InputLayer)        (None, 198)               0         \n",
      "_________________________________________________________________\n",
      "hiddenLayer1 (Dense)         (None, 64)                12736     \n",
      "_________________________________________________________________\n",
      "hiddenLayer2 (Dense)         (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "hiddenLayer3 (Dense)         (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "encode_out (Dense)           (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "hiddenLayer4 (Dense)         (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "hiddenLayer5 (Dense)         (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "hiddenLayer6 (Dense)         (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "decode_out (Dense)           (None, 198)               12870     \n",
      "=================================================================\n",
      "Total params: 30,952\n",
      "Trainable params: 30,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 146.00 629.00\" width=\"146pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-625 142,-625 142,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2164372596328 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2164372596328</title>\n",
       "<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 138,-620.5 138,-584.5 0,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-598.8\">embeding: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2164372596440 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2164372596440</title>\n",
       "<polygon fill=\"none\" points=\"2,-511.5 2,-547.5 136,-547.5 136,-511.5 2,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-525.8\">hiddenLayer1: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372596328&#45;&gt;2164372596440 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2164372596328-&gt;2164372596440</title>\n",
       "<path d=\"M69,-584.313C69,-576.289 69,-566.547 69,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-557.529 69,-547.529 65.5001,-557.529 72.5001,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164372597672 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2164372597672</title>\n",
       "<polygon fill=\"none\" points=\"2,-438.5 2,-474.5 136,-474.5 136,-438.5 2,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-452.8\">hiddenLayer2: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372596440&#45;&gt;2164372597672 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2164372596440-&gt;2164372597672</title>\n",
       "<path d=\"M69,-511.313C69,-503.289 69,-493.547 69,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-484.529 69,-474.529 65.5001,-484.529 72.5001,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164372597168 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2164372597168</title>\n",
       "<polygon fill=\"none\" points=\"2,-365.5 2,-401.5 136,-401.5 136,-365.5 2,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-379.8\">hiddenLayer3: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372597672&#45;&gt;2164372597168 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2164372597672-&gt;2164372597168</title>\n",
       "<path d=\"M69,-438.313C69,-430.289 69,-420.547 69,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-411.529 69,-401.529 65.5001,-411.529 72.5001,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164372597280 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2164372597280</title>\n",
       "<polygon fill=\"none\" points=\"7,-292.5 7,-328.5 131,-328.5 131,-292.5 7,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-306.8\">encode_out: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372597168&#45;&gt;2164372597280 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2164372597168-&gt;2164372597280</title>\n",
       "<path d=\"M69,-365.313C69,-357.289 69,-347.547 69,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-338.529 69,-328.529 65.5001,-338.529 72.5001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164372796696 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2164372796696</title>\n",
       "<polygon fill=\"none\" points=\"2,-219.5 2,-255.5 136,-255.5 136,-219.5 2,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-233.8\">hiddenLayer4: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372597280&#45;&gt;2164372796696 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2164372597280-&gt;2164372796696</title>\n",
       "<path d=\"M69,-292.313C69,-284.289 69,-274.547 69,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-265.529 69,-255.529 65.5001,-265.529 72.5001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164372944152 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2164372944152</title>\n",
       "<polygon fill=\"none\" points=\"2,-146.5 2,-182.5 136,-182.5 136,-146.5 2,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-160.8\">hiddenLayer5: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372796696&#45;&gt;2164372944152 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2164372796696-&gt;2164372944152</title>\n",
       "<path d=\"M69,-219.313C69,-211.289 69,-201.547 69,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-192.529 69,-182.529 65.5001,-192.529 72.5001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164373063160 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2164373063160</title>\n",
       "<polygon fill=\"none\" points=\"2,-73.5 2,-109.5 136,-109.5 136,-73.5 2,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-87.8\">hiddenLayer6: Dense</text>\n",
       "</g>\n",
       "<!-- 2164372944152&#45;&gt;2164373063160 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2164372944152-&gt;2164373063160</title>\n",
       "<path d=\"M69,-146.313C69,-138.289 69,-128.547 69,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-119.529 69,-109.529 65.5001,-119.529 72.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2164373199000 -->\n",
       "<g class=\"node\" id=\"node9\"><title>2164373199000</title>\n",
       "<polygon fill=\"none\" points=\"6.5,-0.5 6.5,-36.5 131.5,-36.5 131.5,-0.5 6.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69\" y=\"-14.8\">decode_out: Dense</text>\n",
       "</g>\n",
       "<!-- 2164373063160&#45;&gt;2164373199000 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2164373063160-&gt;2164373199000</title>\n",
       "<path d=\"M69,-73.3129C69,-65.2895 69,-55.5475 69,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"72.5001,-46.5288 69,-36.5288 65.5001,-46.5289 72.5001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "plot_model(autoencoder, to_file='ModifiedAE.png')\n",
    "SVG(model_to_dot(autoencoder).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0513 - encode_out_loss: 0.0277 - decode_out_loss: 0.0237 - encode_out_mean_squared_error: 0.0277 - decode_out_mean_squared_error: 0.0237 - val_loss: 0.0276 - val_encode_out_loss: 0.0055 - val_decode_out_loss: 0.0221 - val_encode_out_mean_squared_error: 0.0055 - val_decode_out_mean_squared_error: 0.0221\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.0238 - encode_out_loss: 0.0037 - decode_out_loss: 0.0201 - encode_out_mean_squared_error: 0.0037 - decode_out_mean_squared_error: 0.0201 - val_loss: 0.0228 - val_encode_out_loss: 0.0026 - val_decode_out_loss: 0.0201 - val_encode_out_mean_squared_error: 0.0026 - val_decode_out_mean_squared_error: 0.0201\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 0.0201 - encode_out_loss: 0.0020 - decode_out_loss: 0.0181 - encode_out_mean_squared_error: 0.0020 - decode_out_mean_squared_error: 0.0181 - val_loss: 0.0191 - val_encode_out_loss: 0.0016 - val_decode_out_loss: 0.0175 - val_encode_out_mean_squared_error: 0.0016 - val_decode_out_mean_squared_error: 0.0175\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1s 268us/step - loss: 0.0172 - encode_out_loss: 0.0013 - decode_out_loss: 0.0159 - encode_out_mean_squared_error: 0.0013 - decode_out_mean_squared_error: 0.0159 - val_loss: 0.0159 - val_encode_out_loss: 8.9750e-04 - val_decode_out_loss: 0.0150 - val_encode_out_mean_squared_error: 8.9750e-04 - val_decode_out_mean_squared_error: 0.0150\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1s 256us/step - loss: 0.0135 - encode_out_loss: 0.0010 - decode_out_loss: 0.0125 - encode_out_mean_squared_error: 0.0010 - decode_out_mean_squared_error: 0.0125 - val_loss: 0.0113 - val_encode_out_loss: 7.2101e-04 - val_decode_out_loss: 0.0106 - val_encode_out_mean_squared_error: 7.2101e-04 - val_decode_out_mean_squared_error: 0.0106\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.0108 - encode_out_loss: 8.5254e-04 - decode_out_loss: 0.0100 - encode_out_mean_squared_error: 8.5254e-04 - decode_out_mean_squared_error: 0.0100 - val_loss: 0.0106 - val_encode_out_loss: 8.4352e-04 - val_decode_out_loss: 0.0097 - val_encode_out_mean_squared_error: 8.4352e-04 - val_decode_out_mean_squared_error: 0.0097\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0101 - encode_out_loss: 7.4504e-04 - decode_out_loss: 0.0094 - encode_out_mean_squared_error: 7.4504e-04 - decode_out_mean_squared_error: 0.0094 - val_loss: 0.0099 - val_encode_out_loss: 7.4159e-04 - val_decode_out_loss: 0.0091 - val_encode_out_mean_squared_error: 7.4159e-04 - val_decode_out_mean_squared_error: 0.0091\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0097 - encode_out_loss: 6.7754e-04 - decode_out_loss: 0.0090 - encode_out_mean_squared_error: 6.7754e-04 - decode_out_mean_squared_error: 0.0090 - val_loss: 0.0095 - val_encode_out_loss: 6.5093e-04 - val_decode_out_loss: 0.0089 - val_encode_out_mean_squared_error: 6.5093e-04 - val_decode_out_mean_squared_error: 0.0089\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1s 264us/step - loss: 0.0095 - encode_out_loss: 6.5669e-04 - decode_out_loss: 0.0088 - encode_out_mean_squared_error: 6.5669e-04 - decode_out_mean_squared_error: 0.0088 - val_loss: 0.0094 - val_encode_out_loss: 6.5888e-04 - val_decode_out_loss: 0.0087 - val_encode_out_mean_squared_error: 6.5888e-04 - val_decode_out_mean_squared_error: 0.0087\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.0093 - encode_out_loss: 6.4664e-04 - decode_out_loss: 0.0087 - encode_out_mean_squared_error: 6.4664e-04 - decode_out_mean_squared_error: 0.0087 - val_loss: 0.0090 - val_encode_out_loss: 5.4355e-04 - val_decode_out_loss: 0.0084 - val_encode_out_mean_squared_error: 5.4355e-04 - val_decode_out_mean_squared_error: 0.0084\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 0.0091 - encode_out_loss: 5.9322e-04 - decode_out_loss: 0.0085 - encode_out_mean_squared_error: 5.9322e-04 - decode_out_mean_squared_error: 0.0085 - val_loss: 0.0091 - val_encode_out_loss: 6.6528e-04 - val_decode_out_loss: 0.0084 - val_encode_out_mean_squared_error: 6.6528e-04 - val_decode_out_mean_squared_error: 0.0084\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 1s 261us/step - loss: 0.0090 - encode_out_loss: 5.9092e-04 - decode_out_loss: 0.0084 - encode_out_mean_squared_error: 5.9092e-04 - decode_out_mean_squared_error: 0.0084 - val_loss: 0.0087 - val_encode_out_loss: 4.9929e-04 - val_decode_out_loss: 0.0082 - val_encode_out_mean_squared_error: 4.9929e-04 - val_decode_out_mean_squared_error: 0.0082\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.0089 - encode_out_loss: 5.5486e-04 - decode_out_loss: 0.0083 - encode_out_mean_squared_error: 5.5486e-04 - decode_out_mean_squared_error: 0.0083 - val_loss: 0.0086 - val_encode_out_loss: 5.0005e-04 - val_decode_out_loss: 0.0081 - val_encode_out_mean_squared_error: 5.0005e-04 - val_decode_out_mean_squared_error: 0.0081\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.0088 - encode_out_loss: 5.9988e-04 - decode_out_loss: 0.0082 - encode_out_mean_squared_error: 5.9988e-04 - decode_out_mean_squared_error: 0.0082 - val_loss: 0.0086 - val_encode_out_loss: 6.2630e-04 - val_decode_out_loss: 0.0080 - val_encode_out_mean_squared_error: 6.2630e-04 - val_decode_out_mean_squared_error: 0.0080\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0087 - encode_out_loss: 5.9885e-04 - decode_out_loss: 0.0081 - encode_out_mean_squared_error: 5.9885e-04 - decode_out_mean_squared_error: 0.0081 - val_loss: 0.0084 - val_encode_out_loss: 4.9906e-04 - val_decode_out_loss: 0.0079 - val_encode_out_mean_squared_error: 4.9906e-04 - val_decode_out_mean_squared_error: 0.0079\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.0085 - encode_out_loss: 5.7458e-04 - decode_out_loss: 0.0080 - encode_out_mean_squared_error: 5.7458e-04 - decode_out_mean_squared_error: 0.0080 - val_loss: 0.0086 - val_encode_out_loss: 7.4256e-04 - val_decode_out_loss: 0.0078 - val_encode_out_mean_squared_error: 7.4256e-04 - val_decode_out_mean_squared_error: 0.0078\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 0.0085 - encode_out_loss: 5.9834e-04 - decode_out_loss: 0.0079 - encode_out_mean_squared_error: 5.9834e-04 - decode_out_mean_squared_error: 0.0079 - val_loss: 0.0082 - val_encode_out_loss: 5.5262e-04 - val_decode_out_loss: 0.0076 - val_encode_out_mean_squared_error: 5.5262e-04 - val_decode_out_mean_squared_error: 0.0076\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0084 - encode_out_loss: 6.0507e-04 - decode_out_loss: 0.0078 - encode_out_mean_squared_error: 6.0507e-04 - decode_out_mean_squared_error: 0.0078 - val_loss: 0.0083 - val_encode_out_loss: 6.6787e-04 - val_decode_out_loss: 0.0076 - val_encode_out_mean_squared_error: 6.6787e-04 - val_decode_out_mean_squared_error: 0.0076\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 0.0084 - encode_out_loss: 5.8907e-04 - decode_out_loss: 0.0078 - encode_out_mean_squared_error: 5.8907e-04 - decode_out_mean_squared_error: 0.0078 - val_loss: 0.0080 - val_encode_out_loss: 5.6413e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 5.6413e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 0.0083 - encode_out_loss: 5.8337e-04 - decode_out_loss: 0.0077 - encode_out_mean_squared_error: 5.8337e-04 - decode_out_mean_squared_error: 0.0077 - val_loss: 0.0080 - val_encode_out_loss: 5.0788e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 5.0788e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 260us/step - loss: 0.0082 - encode_out_loss: 5.6981e-04 - decode_out_loss: 0.0077 - encode_out_mean_squared_error: 5.6981e-04 - decode_out_mean_squared_error: 0.0077 - val_loss: 0.0081 - val_encode_out_loss: 6.8918e-04 - val_decode_out_loss: 0.0074 - val_encode_out_mean_squared_error: 6.8918e-04 - val_decode_out_mean_squared_error: 0.0074\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 1s 279us/step - loss: 0.0082 - encode_out_loss: 5.8449e-04 - decode_out_loss: 0.0076 - encode_out_mean_squared_error: 5.8449e-04 - decode_out_mean_squared_error: 0.0076 - val_loss: 0.0081 - val_encode_out_loss: 6.4369e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 6.4369e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 1s 256us/step - loss: 0.0081 - encode_out_loss: 5.4301e-04 - decode_out_loss: 0.0076 - encode_out_mean_squared_error: 5.4301e-04 - decode_out_mean_squared_error: 0.0076 - val_loss: 0.0081 - val_encode_out_loss: 6.3149e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 6.3149e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 1s 277us/step - loss: 0.0081 - encode_out_loss: 5.4725e-04 - decode_out_loss: 0.0075 - encode_out_mean_squared_error: 5.4725e-04 - decode_out_mean_squared_error: 0.0075 - val_loss: 0.0079 - val_encode_out_loss: 5.6535e-04 - val_decode_out_loss: 0.0073 - val_encode_out_mean_squared_error: 5.6535e-04 - val_decode_out_mean_squared_error: 0.0073\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 1s 340us/step - loss: 0.0080 - encode_out_loss: 5.5207e-04 - decode_out_loss: 0.0075 - encode_out_mean_squared_error: 5.5207e-04 - decode_out_mean_squared_error: 0.0075 - val_loss: 0.0080 - val_encode_out_loss: 6.0432e-04 - val_decode_out_loss: 0.0073 - val_encode_out_mean_squared_error: 6.0432e-04 - val_decode_out_mean_squared_error: 0.0073\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 1s 260us/step - loss: 0.0080 - encode_out_loss: 5.6591e-04 - decode_out_loss: 0.0075 - encode_out_mean_squared_error: 5.6591e-04 - decode_out_mean_squared_error: 0.0075 - val_loss: 0.0078 - val_encode_out_loss: 5.1864e-04 - val_decode_out_loss: 0.0073 - val_encode_out_mean_squared_error: 5.1864e-04 - val_decode_out_mean_squared_error: 0.0073\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 1s 263us/step - loss: 0.0079 - encode_out_loss: 5.5001e-04 - decode_out_loss: 0.0074 - encode_out_mean_squared_error: 5.5001e-04 - decode_out_mean_squared_error: 0.0074 - val_loss: 0.0080 - val_encode_out_loss: 7.2357e-04 - val_decode_out_loss: 0.0072 - val_encode_out_mean_squared_error: 7.2357e-04 - val_decode_out_mean_squared_error: 0.0072\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 1s 270us/step - loss: 0.0079 - encode_out_loss: 5.4141e-04 - decode_out_loss: 0.0073 - encode_out_mean_squared_error: 5.4141e-04 - decode_out_mean_squared_error: 0.0073 - val_loss: 0.0080 - val_encode_out_loss: 5.3137e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 5.3137e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 1s 266us/step - loss: 0.0078 - encode_out_loss: 5.3810e-04 - decode_out_loss: 0.0073 - encode_out_mean_squared_error: 5.3810e-04 - decode_out_mean_squared_error: 0.0073 - val_loss: 0.0076 - val_encode_out_loss: 4.8889e-04 - val_decode_out_loss: 0.0071 - val_encode_out_mean_squared_error: 4.8889e-04 - val_decode_out_mean_squared_error: 0.0071\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 0s 249us/step - loss: 0.0078 - encode_out_loss: 5.3067e-04 - decode_out_loss: 0.0072 - encode_out_mean_squared_error: 5.3067e-04 - decode_out_mean_squared_error: 0.0072 - val_loss: 0.0080 - val_encode_out_loss: 8.6313e-04 - val_decode_out_loss: 0.0071 - val_encode_out_mean_squared_error: 8.6313e-04 - val_decode_out_mean_squared_error: 0.0071\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0077 - encode_out_loss: 5.4284e-04 - decode_out_loss: 0.0072 - encode_out_mean_squared_error: 5.4284e-04 - decode_out_mean_squared_error: 0.0072 - val_loss: 0.0075 - val_encode_out_loss: 4.8337e-04 - val_decode_out_loss: 0.0070 - val_encode_out_mean_squared_error: 4.8337e-04 - val_decode_out_mean_squared_error: 0.0070\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 1s 287us/step - loss: 0.0077 - encode_out_loss: 5.3269e-04 - decode_out_loss: 0.0071 - encode_out_mean_squared_error: 5.3269e-04 - decode_out_mean_squared_error: 0.0071 - val_loss: 0.0075 - val_encode_out_loss: 5.7120e-04 - val_decode_out_loss: 0.0069 - val_encode_out_mean_squared_error: 5.7120e-04 - val_decode_out_mean_squared_error: 0.0069\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 0.0076 - encode_out_loss: 5.5283e-04 - decode_out_loss: 0.0071 - encode_out_mean_squared_error: 5.5283e-04 - decode_out_mean_squared_error: 0.0071 - val_loss: 0.0077 - val_encode_out_loss: 6.0553e-04 - val_decode_out_loss: 0.0071 - val_encode_out_mean_squared_error: 6.0553e-04 - val_decode_out_mean_squared_error: 0.0071\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.0075 - encode_out_loss: 5.3091e-04 - decode_out_loss: 0.0070 - encode_out_mean_squared_error: 5.3091e-04 - decode_out_mean_squared_error: 0.0070 - val_loss: 0.0074 - val_encode_out_loss: 5.0823e-04 - val_decode_out_loss: 0.0069 - val_encode_out_mean_squared_error: 5.0823e-04 - val_decode_out_mean_squared_error: 0.0069\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.0076 - encode_out_loss: 5.5503e-04 - decode_out_loss: 0.0070 - encode_out_mean_squared_error: 5.5503e-04 - decode_out_mean_squared_error: 0.0070 - val_loss: 0.0075 - val_encode_out_loss: 5.6702e-04 - val_decode_out_loss: 0.0069 - val_encode_out_mean_squared_error: 5.6702e-04 - val_decode_out_mean_squared_error: 0.0069\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.0075 - encode_out_loss: 5.3242e-04 - decode_out_loss: 0.0069 - encode_out_mean_squared_error: 5.3242e-04 - decode_out_mean_squared_error: 0.0069 - val_loss: 0.0073 - val_encode_out_loss: 5.2279e-04 - val_decode_out_loss: 0.0068 - val_encode_out_mean_squared_error: 5.2279e-04 - val_decode_out_mean_squared_error: 0.0068\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 0.0074 - encode_out_loss: 5.4790e-04 - decode_out_loss: 0.0069 - encode_out_mean_squared_error: 5.4790e-04 - decode_out_mean_squared_error: 0.0069 - val_loss: 0.0076 - val_encode_out_loss: 8.3561e-04 - val_decode_out_loss: 0.0067 - val_encode_out_mean_squared_error: 8.3561e-04 - val_decode_out_mean_squared_error: 0.0067\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.0074 - encode_out_loss: 5.5532e-04 - decode_out_loss: 0.0068 - encode_out_mean_squared_error: 5.5532e-04 - decode_out_mean_squared_error: 0.0068 - val_loss: 0.0071 - val_encode_out_loss: 5.3809e-04 - val_decode_out_loss: 0.0066 - val_encode_out_mean_squared_error: 5.3809e-04 - val_decode_out_mean_squared_error: 0.0066\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.0074 - encode_out_loss: 5.7085e-04 - decode_out_loss: 0.0068 - encode_out_mean_squared_error: 5.7085e-04 - decode_out_mean_squared_error: 0.0068 - val_loss: 0.0072 - val_encode_out_loss: 5.8493e-04 - val_decode_out_loss: 0.0067 - val_encode_out_mean_squared_error: 5.8493e-04 - val_decode_out_mean_squared_error: 0.0067\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 0.0073 - encode_out_loss: 5.4787e-04 - decode_out_loss: 0.0067 - encode_out_mean_squared_error: 5.4787e-04 - decode_out_mean_squared_error: 0.0067 - val_loss: 0.0071 - val_encode_out_loss: 5.2548e-04 - val_decode_out_loss: 0.0065 - val_encode_out_mean_squared_error: 5.2548e-04 - val_decode_out_mean_squared_error: 0.0065\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.0072 - encode_out_loss: 5.6638e-04 - decode_out_loss: 0.0067 - encode_out_mean_squared_error: 5.6638e-04 - decode_out_mean_squared_error: 0.0067 - val_loss: 0.0072 - val_encode_out_loss: 6.4385e-04 - val_decode_out_loss: 0.0065 - val_encode_out_mean_squared_error: 6.4385e-04 - val_decode_out_mean_squared_error: 0.0065\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 0.0072 - encode_out_loss: 5.8149e-04 - decode_out_loss: 0.0066 - encode_out_mean_squared_error: 5.8149e-04 - decode_out_mean_squared_error: 0.0066 - val_loss: 0.0072 - val_encode_out_loss: 7.3763e-04 - val_decode_out_loss: 0.0064 - val_encode_out_mean_squared_error: 7.3763e-04 - val_decode_out_mean_squared_error: 0.0064\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 0.0071 - encode_out_loss: 5.9073e-04 - decode_out_loss: 0.0065 - encode_out_mean_squared_error: 5.9073e-04 - decode_out_mean_squared_error: 0.0065 - val_loss: 0.0069 - val_encode_out_loss: 5.6431e-04 - val_decode_out_loss: 0.0063 - val_encode_out_mean_squared_error: 5.6431e-04 - val_decode_out_mean_squared_error: 0.0063\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0071 - encode_out_loss: 6.2204e-04 - decode_out_loss: 0.0065 - encode_out_mean_squared_error: 6.2204e-04 - decode_out_mean_squared_error: 0.0065 - val_loss: 0.0070 - val_encode_out_loss: 7.5698e-04 - val_decode_out_loss: 0.0063 - val_encode_out_mean_squared_error: 7.5698e-04 - val_decode_out_mean_squared_error: 0.0063\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.0071 - encode_out_loss: 6.3700e-04 - decode_out_loss: 0.0064 - encode_out_mean_squared_error: 6.3700e-04 - decode_out_mean_squared_error: 0.0064 - val_loss: 0.0069 - val_encode_out_loss: 6.8283e-04 - val_decode_out_loss: 0.0062 - val_encode_out_mean_squared_error: 6.8283e-04 - val_decode_out_mean_squared_error: 0.0062\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 1s 345us/step - loss: 0.0070 - encode_out_loss: 6.6067e-04 - decode_out_loss: 0.0063 - encode_out_mean_squared_error: 6.6067e-04 - decode_out_mean_squared_error: 0.0063 - val_loss: 0.0072 - val_encode_out_loss: 9.8550e-04 - val_decode_out_loss: 0.0062 - val_encode_out_mean_squared_error: 9.8550e-04 - val_decode_out_mean_squared_error: 0.0062\n",
      "Epoch 47/100\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 0.0069 - encode_out_loss: 6.4191e-04 - decode_out_loss: 0.0063 - encode_out_mean_squared_error: 6.4191e-04 - decode_out_mean_squared_error: 0.0063 - val_loss: 0.0068 - val_encode_out_loss: 5.8499e-04 - val_decode_out_loss: 0.0062 - val_encode_out_mean_squared_error: 5.8499e-04 - val_decode_out_mean_squared_error: 0.0062\n",
      "Epoch 48/100\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.0069 - encode_out_loss: 6.7569e-04 - decode_out_loss: 0.0062 - encode_out_mean_squared_error: 6.7569e-04 - decode_out_mean_squared_error: 0.0062 - val_loss: 0.0071 - val_encode_out_loss: 9.7463e-04 - val_decode_out_loss: 0.0061 - val_encode_out_mean_squared_error: 9.7463e-04 - val_decode_out_mean_squared_error: 0.0061\n",
      "Epoch 49/100\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.0068 - encode_out_loss: 6.7120e-04 - decode_out_loss: 0.0062 - encode_out_mean_squared_error: 6.7120e-04 - decode_out_mean_squared_error: 0.0062 - val_loss: 0.0066 - val_encode_out_loss: 6.4319e-04 - val_decode_out_loss: 0.0060 - val_encode_out_mean_squared_error: 6.4319e-04 - val_decode_out_mean_squared_error: 0.0060\n",
      "Epoch 50/100\n",
      "2000/2000 [==============================] - 1s 263us/step - loss: 0.0067 - encode_out_loss: 6.5284e-04 - decode_out_loss: 0.0061 - encode_out_mean_squared_error: 6.5284e-04 - decode_out_mean_squared_error: 0.0061 - val_loss: 0.0067 - val_encode_out_loss: 7.0044e-04 - val_decode_out_loss: 0.0060 - val_encode_out_mean_squared_error: 7.0044e-04 - val_decode_out_mean_squared_error: 0.0060\n",
      "Epoch 51/100\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.0067 - encode_out_loss: 6.5883e-04 - decode_out_loss: 0.0060 - encode_out_mean_squared_error: 6.5883e-04 - decode_out_mean_squared_error: 0.0060 - val_loss: 0.0065 - val_encode_out_loss: 7.2845e-04 - val_decode_out_loss: 0.0057 - val_encode_out_mean_squared_error: 7.2845e-04 - val_decode_out_mean_squared_error: 0.0057\n",
      "Epoch 52/100\n",
      "2000/2000 [==============================] - 1s 340us/step - loss: 0.0067 - encode_out_loss: 7.0377e-04 - decode_out_loss: 0.0060 - encode_out_mean_squared_error: 7.0377e-04 - decode_out_mean_squared_error: 0.0060 - val_loss: 0.0066 - val_encode_out_loss: 7.4412e-04 - val_decode_out_loss: 0.0059 - val_encode_out_mean_squared_error: 7.4412e-04 - val_decode_out_mean_squared_error: 0.0059\n",
      "Epoch 53/100\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.0066 - encode_out_loss: 6.8248e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 6.8248e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0064 - val_encode_out_loss: 6.9728e-04 - val_decode_out_loss: 0.0057 - val_encode_out_mean_squared_error: 6.9728e-04 - val_decode_out_mean_squared_error: 0.0057\n",
      "Epoch 54/100\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.0067 - encode_out_loss: 7.0561e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 7.0561e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0063 - val_encode_out_loss: 6.5466e-04 - val_decode_out_loss: 0.0057 - val_encode_out_mean_squared_error: 6.5466e-04 - val_decode_out_mean_squared_error: 0.0057\n",
      "Epoch 55/100\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.0065 - encode_out_loss: 6.8036e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 6.8036e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0065 - val_encode_out_loss: 6.8909e-04 - val_decode_out_loss: 0.0058 - val_encode_out_mean_squared_error: 6.8909e-04 - val_decode_out_mean_squared_error: 0.0058\n",
      "Epoch 56/100\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 0.0066 - encode_out_loss: 7.1730e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 7.1730e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0064 - val_encode_out_loss: 6.7357e-04 - val_decode_out_loss: 0.0057 - val_encode_out_mean_squared_error: 6.7357e-04 - val_decode_out_mean_squared_error: 0.0057\n",
      "Epoch 57/100\n",
      "2000/2000 [==============================] - 1s 270us/step - loss: 0.0065 - encode_out_loss: 6.9261e-04 - decode_out_loss: 0.0058 - encode_out_mean_squared_error: 6.9261e-04 - decode_out_mean_squared_error: 0.0058 - val_loss: 0.0063 - val_encode_out_loss: 7.0730e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 7.0730e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 58/100\n",
      "2000/2000 [==============================] - 1s 255us/step - loss: 0.0065 - encode_out_loss: 7.1255e-04 - decode_out_loss: 0.0058 - encode_out_mean_squared_error: 7.1255e-04 - decode_out_mean_squared_error: 0.0058 - val_loss: 0.0064 - val_encode_out_loss: 7.2923e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 7.2923e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 59/100\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.0065 - encode_out_loss: 7.1265e-04 - decode_out_loss: 0.0058 - encode_out_mean_squared_error: 7.1265e-04 - decode_out_mean_squared_error: 0.0058 - val_loss: 0.0067 - val_encode_out_loss: 8.3215e-04 - val_decode_out_loss: 0.0059 - val_encode_out_mean_squared_error: 8.3215e-04 - val_decode_out_mean_squared_error: 0.0059\n",
      "Epoch 60/100\n",
      "2000/2000 [==============================] - 1s 257us/step - loss: 0.0064 - encode_out_loss: 6.9399e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 6.9399e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0063 - val_encode_out_loss: 6.1664e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 6.1664e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 277us/step - loss: 0.0064 - encode_out_loss: 7.0227e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 7.0227e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0062 - val_encode_out_loss: 6.7142e-04 - val_decode_out_loss: 0.0055 - val_encode_out_mean_squared_error: 6.7142e-04 - val_decode_out_mean_squared_error: 0.0055\n",
      "Epoch 62/100\n",
      "2000/2000 [==============================] - 0s 247us/step - loss: 0.0064 - encode_out_loss: 7.4402e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 7.4402e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0062 - val_encode_out_loss: 6.1628e-04 - val_decode_out_loss: 0.0055 - val_encode_out_mean_squared_error: 6.1628e-04 - val_decode_out_mean_squared_error: 0.0055\n",
      "Epoch 63/100\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 0.0063 - encode_out_loss: 7.1962e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 7.1962e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0063 - val_encode_out_loss: 7.1651e-04 - val_decode_out_loss: 0.0055 - val_encode_out_mean_squared_error: 7.1651e-04 - val_decode_out_mean_squared_error: 0.0055\n",
      "Epoch 64/100\n",
      "2000/2000 [==============================] - 1s 260us/step - loss: 0.0064 - encode_out_loss: 7.1444e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 7.1444e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0062 - val_encode_out_loss: 7.8231e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 7.8231e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 65/100\n",
      "2000/2000 [==============================] - 1s 255us/step - loss: 0.0062 - encode_out_loss: 6.9072e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 6.9072e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0060 - val_encode_out_loss: 6.3088e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.3088e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 66/100\n",
      "2000/2000 [==============================] - 1s 264us/step - loss: 0.0062 - encode_out_loss: 6.8627e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 6.8627e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0060 - val_encode_out_loss: 6.8174e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.8174e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 67/100\n",
      "2000/2000 [==============================] - 1s 257us/step - loss: 0.0063 - encode_out_loss: 7.0132e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 7.0132e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0060 - val_encode_out_loss: 6.5938e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.5938e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 68/100\n",
      "2000/2000 [==============================] - 1s 260us/step - loss: 0.0062 - encode_out_loss: 7.0458e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 7.0458e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0060 - val_encode_out_loss: 6.5780e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.5780e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 69/100\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 0.0062 - encode_out_loss: 6.8599e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 6.8599e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0060 - val_encode_out_loss: 7.6393e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 7.6393e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 70/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0061 - encode_out_loss: 6.7011e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.7011e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0060 - val_encode_out_loss: 5.9209e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.9209e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 71/100\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.0061 - encode_out_loss: 6.5546e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.5546e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0059 - val_encode_out_loss: 5.7886e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.7886e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 72/100\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 0.0062 - encode_out_loss: 6.8166e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 6.8166e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0059 - val_encode_out_loss: 6.0599e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.0599e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 73/100\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 0.0061 - encode_out_loss: 6.6389e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.6389e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0058 - val_encode_out_loss: 6.0443e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 6.0443e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 74/100\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 0.0060 - encode_out_loss: 6.4056e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.4056e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0065 - val_encode_out_loss: 8.6502e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 8.6502e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 75/100\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.0061 - encode_out_loss: 6.8279e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 6.8279e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0059 - val_encode_out_loss: 6.3443e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.3443e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0060 - encode_out_loss: 6.4204e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.4204e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0059 - val_encode_out_loss: 5.6790e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.6790e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0060 - encode_out_loss: 6.2602e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.2602e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0059 - val_encode_out_loss: 5.8337e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.8337e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 0.0060 - encode_out_loss: 6.2712e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.2712e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0061 - val_encode_out_loss: 6.4389e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.4389e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 79/100\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.0060 - encode_out_loss: 6.4320e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.4320e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0059 - val_encode_out_loss: 6.3936e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 6.3936e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0060 - encode_out_loss: 6.3530e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.3530e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0059 - val_encode_out_loss: 5.8429e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.8429e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 279us/step - loss: 0.0060 - encode_out_loss: 6.3026e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.3026e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.3165e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.3165e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 0.0060 - encode_out_loss: 6.5630e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 6.5630e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0058 - val_encode_out_loss: 5.8946e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.8946e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.0059 - encode_out_loss: 6.0533e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.0533e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0058 - val_encode_out_loss: 5.7879e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.7879e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.0059 - encode_out_loss: 6.3058e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.3058e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0060 - val_encode_out_loss: 6.9463e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.9463e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 0.0059 - encode_out_loss: 6.2296e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.2296e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.7733e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.7733e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - 1s 262us/step - loss: 0.0059 - encode_out_loss: 5.9386e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.9386e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0061 - val_encode_out_loss: 6.7848e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.7848e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - 1s 258us/step - loss: 0.0059 - encode_out_loss: 6.2083e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.2083e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.2475e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.2475e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - 1s 263us/step - loss: 0.0059 - encode_out_loss: 6.0604e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.0604e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.9386e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.9386e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - 1s 255us/step - loss: 0.0059 - encode_out_loss: 6.0744e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.0744e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0058 - val_encode_out_loss: 6.0904e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 6.0904e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - 1s 259us/step - loss: 0.0059 - encode_out_loss: 6.1509e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.1509e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.7325e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.7325e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 0.0059 - encode_out_loss: 6.2020e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 6.2020e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0059 - val_encode_out_loss: 6.3281e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.3281e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0058 - encode_out_loss: 5.8505e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.8505e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0058 - val_encode_out_loss: 6.0257e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 6.0257e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - 1s 270us/step - loss: 0.0058 - encode_out_loss: 5.9915e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.9915e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0061 - val_encode_out_loss: 6.9236e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.9236e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - 1s 255us/step - loss: 0.0058 - encode_out_loss: 6.0869e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 6.0869e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0055 - val_encode_out_loss: 5.3559e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 5.3559e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 0.0058 - encode_out_loss: 5.8833e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.8833e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0061 - val_encode_out_loss: 9.2963e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 9.2963e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - 1s 260us/step - loss: 0.0058 - encode_out_loss: 5.8904e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.8904e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0056 - val_encode_out_loss: 6.3122e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 6.3122e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0058 - encode_out_loss: 6.0309e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 6.0309e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0058 - val_encode_out_loss: 5.9290e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.9290e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 0.0058 - encode_out_loss: 5.9229e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.9229e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0057 - val_encode_out_loss: 6.0847e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 6.0847e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.0057 - encode_out_loss: 5.5882e-04 - decode_out_loss: 0.0051 - encode_out_mean_squared_error: 5.5882e-04 - decode_out_mean_squared_error: 0.0051 - val_loss: 0.0055 - val_encode_out_loss: 5.1311e-04 - val_decode_out_loss: 0.0049 - val_encode_out_mean_squared_error: 5.1311e-04 - val_decode_out_mean_squared_error: 0.0049\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 1s 265us/step - loss: 0.0057 - encode_out_loss: 5.7892e-04 - decode_out_loss: 0.0051 - encode_out_mean_squared_error: 5.7892e-04 - decode_out_mean_squared_error: 0.0051 - val_loss: 0.0066 - val_encode_out_loss: 7.9465e-04 - val_decode_out_loss: 0.0058 - val_encode_out_mean_squared_error: 7.9465e-04 - val_decode_out_mean_squared_error: 0.0058\n"
     ]
    }
   ],
   "source": [
    "history=autoencoder.fit(Y_scaled_train,[X_scaled_train, Y_scaled_train],\n",
    "                shuffle=True,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                validation_data=(Y_scaled_test,[X_scaled_test,Y_scaled_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_model.h5')\n",
    "del autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the previous model and utilise the decoder part to predict the given testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "#decoded_h = Dense(intermediate_dim, activation=\"relu\", name=\"hiddenLayer2\")(decoder_input)\n",
    "#decoded = Dense(original_dim, activation='relu', name=\"decode_out\")(decoded_h)\n",
    "\n",
    "decoded_h_1= Dense(intermediate_dim_1,kernel_initializer='normal', activation='relu', name=\"hiddenLayer4\")(decoder_input)\n",
    "decoded_h_2= Dense(intermediate_dim_2,kernel_initializer='normal', activation='relu', name=\"hiddenLayer5\")(decoded_h_1)\n",
    "decoded_h_3= Dense(intermediate_dim_3,kernel_initializer='normal', activation='relu', name=\"hiddenLayer6\")(decoded_h_2)\n",
    "decoded = Dense(original_dim,kernel_initializer='normal', activation='sigmoid', name=\"decode_out\")(decoded_h_3)\n",
    "\n",
    "generator = Model(decoder_input, decoded)\n",
    "# load weights from first model by name\n",
    "generator.load_weights('autoencoder_model.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training and testing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f7f3f1eef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "hiddenLayer4 (Dense)         (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "hiddenLayer5 (Dense)         (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "hiddenLayer6 (Dense)         (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "decode_out (Dense)           (None, 198)               12870     \n",
      "=================================================================\n",
      "Total params: 15,574\n",
      "Trainable params: 15,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 2), (500, 198))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_test.shape, Y_scaled_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the 7 testing structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset=pd.read_csv('./Ala13/new_testing_data_7.csv',names=['PCA1','PCA2'])\n",
    "predict_dataset.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset=scalar1.transform(predict_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the 7 testing structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23769924 0.632008   0.2142971  ... 0.8410016  0.8391993  0.45276335]\n",
      " [0.28619933 0.7484152  0.3297595  ... 0.20682988 0.2697998  0.55449843]\n",
      " [0.24031763 0.76813376 0.42356506 ... 0.25058746 0.5184897  0.34048927]\n",
      " ...\n",
      " [0.29478195 0.321959   0.88936955 ... 0.12394996 0.33340165 0.5180512 ]\n",
      " [0.26606458 0.30640936 0.88634723 ... 0.3097649  0.46840134 0.2937768 ]\n",
      " [0.24825594 0.2651625  0.8775919  ... 0.31508204 0.30160454 0.8411553 ]]\n"
     ]
    }
   ],
   "source": [
    "pred=generator.predict(predict_dataset, batch_size=16)\n",
    "print(pred)\n",
    "save=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=scalar2.inverse_transform(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.57689083, 32.89801655, 26.45265239, ..., 31.92043376,\n",
       "        26.82715436, 20.65283806],\n",
       "       [28.07402518, 33.788053  , 27.73889473, ..., 18.27385331,\n",
       "        16.38266442, 22.65714283],\n",
       "       [27.60372976, 33.93881917, 28.78388137, ..., 19.21546178,\n",
       "        20.94438135, 18.44090228],\n",
       "       ...,\n",
       "       [28.16199854, 30.52741543, 33.97290754, ..., 16.49038134,\n",
       "        17.5493126 , 21.93908818],\n",
       "       [27.86764053, 30.40852465, 33.9392392 , ..., 20.48888591,\n",
       "        20.02561073, 17.52061011],\n",
       "       [27.68509882, 30.09315564, 33.84170554, ..., 20.60330435,\n",
       "        16.96605848, 28.30463113]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.576891</td>\n",
       "      <td>32.898017</td>\n",
       "      <td>26.452652</td>\n",
       "      <td>27.498199</td>\n",
       "      <td>32.100820</td>\n",
       "      <td>27.450159</td>\n",
       "      <td>26.369065</td>\n",
       "      <td>31.389365</td>\n",
       "      <td>27.326371</td>\n",
       "      <td>28.628122</td>\n",
       "      <td>...</td>\n",
       "      <td>19.770326</td>\n",
       "      <td>31.626568</td>\n",
       "      <td>26.319072</td>\n",
       "      <td>20.476518</td>\n",
       "      <td>31.765425</td>\n",
       "      <td>26.319023</td>\n",
       "      <td>20.266507</td>\n",
       "      <td>31.920434</td>\n",
       "      <td>26.827154</td>\n",
       "      <td>20.652838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.074025</td>\n",
       "      <td>33.788053</td>\n",
       "      <td>27.738895</td>\n",
       "      <td>27.828004</td>\n",
       "      <td>32.847460</td>\n",
       "      <td>28.623116</td>\n",
       "      <td>26.925536</td>\n",
       "      <td>32.057180</td>\n",
       "      <td>28.138802</td>\n",
       "      <td>29.039290</td>\n",
       "      <td>...</td>\n",
       "      <td>22.327568</td>\n",
       "      <td>18.454746</td>\n",
       "      <td>16.357615</td>\n",
       "      <td>22.562991</td>\n",
       "      <td>18.426316</td>\n",
       "      <td>16.259373</td>\n",
       "      <td>22.716376</td>\n",
       "      <td>18.273853</td>\n",
       "      <td>16.382664</td>\n",
       "      <td>22.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.603730</td>\n",
       "      <td>33.938819</td>\n",
       "      <td>28.783881</td>\n",
       "      <td>27.444845</td>\n",
       "      <td>32.932098</td>\n",
       "      <td>29.341796</td>\n",
       "      <td>26.711798</td>\n",
       "      <td>32.257410</td>\n",
       "      <td>28.644018</td>\n",
       "      <td>28.639234</td>\n",
       "      <td>...</td>\n",
       "      <td>19.098040</td>\n",
       "      <td>19.304901</td>\n",
       "      <td>21.181751</td>\n",
       "      <td>18.713751</td>\n",
       "      <td>19.121224</td>\n",
       "      <td>21.040019</td>\n",
       "      <td>18.440740</td>\n",
       "      <td>19.215462</td>\n",
       "      <td>20.944381</td>\n",
       "      <td>18.440902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.953681</td>\n",
       "      <td>30.438137</td>\n",
       "      <td>33.947702</td>\n",
       "      <td>28.928762</td>\n",
       "      <td>30.684510</td>\n",
       "      <td>33.275026</td>\n",
       "      <td>29.889331</td>\n",
       "      <td>30.097888</td>\n",
       "      <td>33.897522</td>\n",
       "      <td>28.843112</td>\n",
       "      <td>...</td>\n",
       "      <td>19.009457</td>\n",
       "      <td>19.140041</td>\n",
       "      <td>19.552353</td>\n",
       "      <td>18.888543</td>\n",
       "      <td>19.027230</td>\n",
       "      <td>19.297281</td>\n",
       "      <td>18.644801</td>\n",
       "      <td>19.062834</td>\n",
       "      <td>19.275901</td>\n",
       "      <td>18.680212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.161999</td>\n",
       "      <td>30.527415</td>\n",
       "      <td>33.972908</td>\n",
       "      <td>29.115865</td>\n",
       "      <td>30.775361</td>\n",
       "      <td>33.350912</td>\n",
       "      <td>30.027998</td>\n",
       "      <td>30.183057</td>\n",
       "      <td>33.960308</td>\n",
       "      <td>29.048795</td>\n",
       "      <td>...</td>\n",
       "      <td>22.212005</td>\n",
       "      <td>16.767869</td>\n",
       "      <td>17.634442</td>\n",
       "      <td>22.127745</td>\n",
       "      <td>16.453635</td>\n",
       "      <td>17.376274</td>\n",
       "      <td>22.207597</td>\n",
       "      <td>16.490381</td>\n",
       "      <td>17.549313</td>\n",
       "      <td>21.939088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.867641</td>\n",
       "      <td>30.408525</td>\n",
       "      <td>33.939239</td>\n",
       "      <td>28.845721</td>\n",
       "      <td>30.649058</td>\n",
       "      <td>33.243824</td>\n",
       "      <td>29.820058</td>\n",
       "      <td>30.066244</td>\n",
       "      <td>33.872018</td>\n",
       "      <td>28.760363</td>\n",
       "      <td>...</td>\n",
       "      <td>17.896152</td>\n",
       "      <td>20.483544</td>\n",
       "      <td>20.389887</td>\n",
       "      <td>17.759949</td>\n",
       "      <td>20.412395</td>\n",
       "      <td>20.134910</td>\n",
       "      <td>17.425805</td>\n",
       "      <td>20.488886</td>\n",
       "      <td>20.025611</td>\n",
       "      <td>17.520610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.685099</td>\n",
       "      <td>30.093156</td>\n",
       "      <td>33.841706</td>\n",
       "      <td>28.591374</td>\n",
       "      <td>30.143463</td>\n",
       "      <td>33.353859</td>\n",
       "      <td>29.165158</td>\n",
       "      <td>29.441455</td>\n",
       "      <td>34.049763</td>\n",
       "      <td>28.735232</td>\n",
       "      <td>...</td>\n",
       "      <td>27.790651</td>\n",
       "      <td>20.781904</td>\n",
       "      <td>17.301810</td>\n",
       "      <td>28.155882</td>\n",
       "      <td>20.636580</td>\n",
       "      <td>17.147866</td>\n",
       "      <td>28.587948</td>\n",
       "      <td>20.603304</td>\n",
       "      <td>16.966058</td>\n",
       "      <td>28.304631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0  27.576891  32.898017  26.452652  27.498199  32.100820  27.450159   \n",
       "1  28.074025  33.788053  27.738895  27.828004  32.847460  28.623116   \n",
       "2  27.603730  33.938819  28.783881  27.444845  32.932098  29.341796   \n",
       "3  27.953681  30.438137  33.947702  28.928762  30.684510  33.275026   \n",
       "4  28.161999  30.527415  33.972908  29.115865  30.775361  33.350912   \n",
       "5  27.867641  30.408525  33.939239  28.845721  30.649058  33.243824   \n",
       "6  27.685099  30.093156  33.841706  28.591374  30.143463  33.353859   \n",
       "\n",
       "         6          7          8          9      ...            188  \\\n",
       "0  26.369065  31.389365  27.326371  28.628122    ...      19.770326   \n",
       "1  26.925536  32.057180  28.138802  29.039290    ...      22.327568   \n",
       "2  26.711798  32.257410  28.644018  28.639234    ...      19.098040   \n",
       "3  29.889331  30.097888  33.897522  28.843112    ...      19.009457   \n",
       "4  30.027998  30.183057  33.960308  29.048795    ...      22.212005   \n",
       "5  29.820058  30.066244  33.872018  28.760363    ...      17.896152   \n",
       "6  29.165158  29.441455  34.049763  28.735232    ...      27.790651   \n",
       "\n",
       "         189        190        191        192        193        194  \\\n",
       "0  31.626568  26.319072  20.476518  31.765425  26.319023  20.266507   \n",
       "1  18.454746  16.357615  22.562991  18.426316  16.259373  22.716376   \n",
       "2  19.304901  21.181751  18.713751  19.121224  21.040019  18.440740   \n",
       "3  19.140041  19.552353  18.888543  19.027230  19.297281  18.644801   \n",
       "4  16.767869  17.634442  22.127745  16.453635  17.376274  22.207597   \n",
       "5  20.483544  20.389887  17.759949  20.412395  20.134910  17.425805   \n",
       "6  20.781904  17.301810  28.155882  20.636580  17.147866  28.587948   \n",
       "\n",
       "         195        196        197  \n",
       "0  31.920434  26.827154  20.652838  \n",
       "1  18.273853  16.382664  22.657143  \n",
       "2  19.215462  20.944381  18.440902  \n",
       "3  19.062834  19.275901  18.680212  \n",
       "4  16.490381  17.549313  21.939088  \n",
       "5  20.488886  20.025611  17.520610  \n",
       "6  20.603304  16.966058  28.304631  \n",
       "\n",
       "[7 rows x 198 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('new_results_7.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
